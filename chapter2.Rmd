# Regression and model validation
# Heli Helskyaho

*Describe the work this week and summarize your learning.*

- Describe your work and results clearly. 
- Assume the reader has an introductory course level understanding of writing and reading R code as well as statistical methods.
- Assume the reader has no previous knowledge of your data or the more advanced methods you are using.

```{r}
date()
ds <- read.csv("C:/Users/Heli/Heli/HY/Introduction to Open Data Science/Projects/IODS-project/data\\learning2014.csv", header=TRUE)
ds$Points
dim(ds)
str(ds)
summary(ds)

```
The dataset contains 166 rows and  7 columns.
It includes the gender (F/M), the age, the points and some combination variables built using mean. 
These variables and the original variables they are combined are:

# attitude: Aa, Ab, Ac, Ad, Ae, Af
# deep: D03+D11+D19+D27, D07+D14+D22+D30, D06+D15+D23+D31
# surf: SU02+SU10+SU18+SU26, SU05+SU13+SU21+SU29, SU08+SU16+SU24+SU32
# stra: ST01+ST09+ST17+ST25, ST04+ST12+ST20+ST28

Gender is of type chr, age and points are of type int and the rest of the variables are of type num as shown here:
'data.frame':	166 obs. of  7 variables:
 $ X.gender.  : chr  "\"F\"" "\"M\"" "\"F\"" "\"M\"" ...
 $ X.Age.     : int  53 55 49 53 49 38 50 37 37 42 ...
 $ X.attitude.: num  1.5 1.67 1.5 2.17 1.83 ...
 $ X.deep.    : num  3.58 2.92 3.5 3.5 3.67 ...
 $ X.stra.    : num  3.38 2.75 3.62 3.12 3.62 ...
 $ X.surf.    : num  2.58 3.17 2.25 2.25 2.83 ...
 $ X.Points.  : int  25 12 24 10 22 21 21 31 24 26 ...
 
 The minimum age in the dataset is 17, maximum 55. Values for attitude are between 1.000-4.667, for deep between 1.583-4.917, stra 1.250-5.000, and surf 1.583-4.333. The minimum points are 7.00 and the maximum points are 33.00. The table below shows also the 1st quadrant, median, mean, and 3. quadrant for each variable.

   X.gender.             X.Age.       X.attitude.       X.deep.         X.stra.         X.surf.     
 Length:166         Min.   :17.00   Min.   :1.000   Min.   :1.583   Min.   :1.250   Min.   :1.583  
 Class :character   1st Qu.:21.00   1st Qu.:1.500   1st Qu.:3.333   1st Qu.:2.625   1st Qu.:2.417  
 Mode  :character   Median :22.00   Median :1.667   Median :3.667   Median :3.188   Median :2.833  
                    Mean   :25.51   Mean   :1.883   Mean   :3.680   Mean   :3.121   Mean   :2.787  
                    3rd Qu.:27.00   3rd Qu.:2.000   3rd Qu.:4.083   3rd Qu.:3.625   3rd Qu.:3.167  
                    Max.   :55.00   Max.   :4.667   Max.   :4.917   Max.   :5.000   Max.   :4.333  
   X.Points.    
 Min.   : 7.00  
 1st Qu.:19.00  
 Median :23.00  
 Mean   :22.72  
 3rd Qu.:27.75  
 Max.   :33.00  

```{r}
pairs(ds[-1])
```
The scatter plot above describes the relationships between the variables. We have removed gender from the scatter plot.

```{r}
library(GGally)
library(ggplot2)
p <- ggpairs(ds, mapping = aes(), lower = list(combo = wrap("facethist", bins = 20)))
p
```
Above you can see a more advanced plot describing for instance the correlation of different variables to each others and the distribuiton of each variable.
```{r}
# a scatter plot of points versus attitude
library(ggplot2)
# colnames(learning2014)[7] <- "points"

qplot(attitude, Points, data = ds) + geom_smooth(method = "lm")

```

```{r}
my_model <- lm(Points  ~ attitude + deep + Age, data = ds )
summary(my_model)
```
Residuals explain the minimum and maximum values that are -16.0562 and 10.7479. It also shows that the median is 0.2952, the first quatrain is -3.7634 and the third is 4.6517.
The t-value measures the size of the difference relative to the variation, so the bigger the number the greater the evidence against the null hypothesis. Age seems to have the biggest difference (-1.197) but still not big enough to refute the 0-hypotheses. The t-value cannot refute null hypotheses, not statistically significant.
p-value (Pr) is smallest with Age (0.233) but still bigger than 0.05 so none of these are statistically significant.
Based on the results, null hypotheses cannot be refute.
Residual standard error is 5.921. R-squared values indicate explain how well the variance is explained by the model.
Multiple R-squared (0.009356) and	Adjusted R-squared (-0.008989) are almost the same and explaind the variant very poorely. 
```{r}
my_model <- lm(Points  ~ stra + surf +gender, data = ds )
summary(my_model)
```
```{r}
confint(my_model)
```
```{r}
my_model <- lm(Points  ~ attitude, data = ds )
summary(my_model)
```
NOt significant
```{r}
my_model <- lm(Points  ~ deep, data = ds )
summary(my_model)
```
Not significant
```{r}
my_model <- lm(Points  ~ Age, data = ds )
summary(my_model)
```
Not significant
```{r}
my_model <- lm(Points  ~ stra, data = ds )
summary(my_model)
```
Not significant
```{r}
my_model <- lm(Points  ~ surf, data = ds )
summary(my_model)
```
Not significant
```{r}
my_model <- lm(Points  ~ gender, data = ds )
summary(my_model)
```
Not significant.
We choose stra for further investigation. (biggest t-value)
```{r}
my_model <- lm(Points  ~ stra, data = ds )
plot(ds$stra,ds$Points)
abline(my_model, col="red")
my_model
summary(my_model)
```
```{r}
qqnorm(ds$Points, pch = 1, frame = FALSE)
qqline(ds$Points, col = "steelblue", lwd = 2)
```
```{r}
plot(lm(Points~stra,data=ds)) 
```

The assumption is that the strategic approach (stra) defines the overall points (Points): Points is modelled as a linear combination of stra.
Residual is the difference between an observed value of the response variable and the fitted value, the error. Residuals can be used to define the validity of the model assumptions. 
There are several assumptions for the errors. First of them is that they are normally distributed.
QQ-plot of the residuals is a method to explore the assumption that the errors of the model are normally distributed.
The better the data points aline with the line the better they are normally distributed.
In our example QQ-plot the beginning and end of the line do not follow but in the middle the data point are quite well following the line. We could say the errors are well fitting the line with values -1 and 1.5, reasonably well with values less than -1, not so well fitting with values larger than 1.5. Therefore the errors are reasonable well normally distributed.
The second assumption is the constant variance of errors, the size of the errors is not dependent on the explanatory variables. This can be explored with a scatter plot of residuals versus model predictions. Any patter in the scatter plot implies that there is a problem with this assumption. In our example there is no patter to be found and therefore this assumption is correct.
Leverage is used to measure how much impact an observation has to the model. Residuals vs leverage plot can be used to find observations that have unusually high impact, the outliers. In our example there are no outliers.



